{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, alpha=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "    if i % (iterations / 10) == 0:\n",
    "        print(i, W, err)\n",
    "    return W, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_std_feat(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450,\n",
    "               800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2, 1, 3, 3, 1, 2]], dtype = np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-7d5907c1794a>:2: RuntimeWarning: divide by zero encountered in log\n",
      "  err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
      "<ipython-input-10-7d5907c1794a>:2: RuntimeWarning: invalid value encountered in multiply\n",
      "  err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 [ 0.49314177 -0.14151841 -0.00414786  1.52547952] 0.8471318040263481\n"
     ]
    }
   ],
   "source": [
    "W = eval_model(X, y, iterations=5000, alpha=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_st = X.copy()\n",
    "X_st[2, :] = calc_std_feat(X[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_param(iterations, alphas):\n",
    "    best = [999, 0, 0]\n",
    "    for iteration in iterations:\n",
    "        for alfa in alphas:\n",
    "            print(f'iteration: {iteration}, alfa: {alfa}')\n",
    "            W, err = eval_model(X_st, y, iterations=iteration, alpha=alfa)\n",
    "            if err < best[0]:\n",
    "                best = [err, iteration, alfa]\n",
    "    print(f'Лучшие параметры iteration={best[1]}, alfa={best[2]} со значением err={best[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 10000, alfa: 0.1\n",
      "10000 [-11.27241705  -1.45342424  -2.38315559   9.49424167] 0.2523832489493557\n",
      "iteration: 10000, alfa: 0.01\n",
      "10000 [-2.77079473 -0.99580928  0.56650766  3.2676589 ] 0.4058305387773311\n",
      "iteration: 10000, alfa: 0.05\n",
      "10000 [-7.85466344 -1.19933686 -1.28738111  6.80540153] 0.2931230243955608\n",
      "iteration: 10000, alfa: 0.001\n",
      "10000 [-0.29756287 -0.72669083  1.06148576  1.39664388] 0.5233563729128639\n",
      "iteration: 10000, alfa: 0.005\n",
      "10000 [-1.53715836 -0.94411088  0.98699727  2.45300573] 0.45341030857737563\n",
      "iteration: 10000, alfa: 0.0001\n",
      "10000 [ 0.25808924 -0.68189547  0.68834749  1.2411954 ] 0.5906743816929662\n",
      "iteration: 10000, alfa: 0.0005\n",
      "10000 [-0.06997385 -0.68665886  0.94957377  1.2441334 ] 0.5416456771092769\n",
      "iteration: 10000, alfa: 1e-05\n",
      "10000 [ 0.45886981 -0.25439705  0.6453131   1.46695998] 1.0393648355410017\n",
      "iteration: 50000, alfa: 0.1\n",
      "50000 [-26.07030122  -2.7286846   -6.81038328  21.47869092] 0.1509953864560301\n",
      "iteration: 50000, alfa: 0.01\n",
      "50000 [-7.85441079 -1.19932069 -1.28729658  6.80520914] 0.293121857730925\n",
      "iteration: 50000, alfa: 0.05\n",
      "50000 [-18.28269129  -2.04553109  -4.51665252  15.16392565] 0.19411441176369898\n",
      "iteration: 50000, alfa: 0.001\n",
      "50000 [-1.53714022 -0.94409864  0.98698237  2.45297533] 0.4534064727730054\n",
      "iteration: 50000, alfa: 0.005\n",
      "50000 [-5.2937412  -1.06076574 -0.39931106  4.92606362] 0.33738226208825006\n",
      "iteration: 50000, alfa: 0.0001\n",
      "50000 [-0.06996594 -0.6866606   0.94956256  1.24413705] 0.541644374202672\n",
      "iteration: 50000, alfa: 0.0005\n",
      "50000 [-0.80146307 -0.84900669  1.11418378  1.87182387] 0.48983598782871285\n",
      "iteration: 50000, alfa: 1e-05\n",
      "50000 [ 0.34114163 -0.58524253  0.6460506   1.30593418] 0.6416702824336051\n",
      "iteration: 100000, alfa: 0.1\n",
      "100000 [-35.8933164   -3.59426199  -9.64639296  29.4060647 ] 0.11667060791100073\n",
      "iteration: 100000, alfa: 0.01\n",
      "100000 [-11.27192801  -1.45338517  -2.38300258   9.49385018] 0.25238285377547093\n",
      "iteration: 100000, alfa: 0.05\n",
      "100000 [-26.07012983  -2.72866947  -6.81033337  21.47855215] 0.15099558191549056\n",
      "iteration: 100000, alfa: 0.001\n",
      "100000 [-2.77073816 -0.9958014   0.56651721  3.26761217] 0.40582576219273137\n",
      "iteration: 100000, alfa: 0.005\n",
      "100000 [-7.85437925 -1.19931868 -1.28728603  6.80518513] 0.2931217112350516\n",
      "iteration: 100000, alfa: 0.0001\n",
      "100000 [-0.29755454 -0.72668938  1.06147096  1.3966418 ] 0.5233543557317325\n",
      "iteration: 100000, alfa: 0.0005\n",
      "100000 [-1.53713795 -0.94409711  0.98698051  2.45297153] 0.45340599323974795\n",
      "iteration: 100000, alfa: 1e-05\n",
      "100000 [ 0.25809285 -0.68188567  0.6883469   1.2412009 ] 0.5906726973128931\n",
      "iteration: 150000, alfa: 0.1\n",
      "150000 [-42.58016954  -4.1712215  -11.56630967  34.75695793] 0.10108464416583582\n",
      "iteration: 150000, alfa: 0.01\n",
      "150000 [-13.94273846  -1.67368786  -3.20718149  11.64582983] 0.2273363155534241\n",
      "iteration: 150000, alfa: 0.05\n",
      "150000 [-31.57995252  -3.21533568  -8.405804    25.9326696 ] 0.12965903836455317\n",
      "iteration: 150000, alfa: 0.001\n",
      "150000 [-3.76553277 -1.01496655  0.17888663  3.90129479] 0.37489169997699323\n",
      "iteration: 150000, alfa: 0.005\n",
      "150000 [-9.71021179 -1.33137896 -1.89027511  8.25042085] 0.26937742089690586\n",
      "iteration: 150000, alfa: 0.0001\n",
      "150000 [-0.47652571 -0.77417761  1.10219985  1.5667623 ] 0.5103437008650245\n",
      "iteration: 150000, alfa: 0.0005\n",
      "150000 [-2.18897009 -0.97995031  0.78173642  2.89506994] 0.42680096067833195\n",
      "iteration: 150000, alfa: 1e-05\n",
      "150000 [ 0.1985885  -0.69519903  0.73586672  1.22062872] 0.5776128288879383\n",
      "iteration: 200000, alfa: 0.1\n",
      "200000 [-47.83523093  -4.60958703 -13.08107424  38.92379106] 0.09156004715343082\n",
      "iteration: 200000, alfa: 0.01\n",
      "200000 [-16.2422902   -1.86937288  -3.90462901  13.50867797] 0.2087444482151381\n",
      "iteration: 200000, alfa: 0.05\n",
      "200000 [-35.89319236  -3.59425115  -9.64635734  29.40596502] 0.11667073266786669\n",
      "iteration: 200000, alfa: 0.001\n",
      "200000 [-4.5902344  -1.03597991 -0.13798412  4.44453591] 0.35332021016068815\n",
      "iteration: 200000, alfa: 0.005\n",
      "200000 [-11.27190091  -1.453383    -2.3829941    9.49382849] 0.25238283105355996\n",
      "iteration: 200000, alfa: 0.0001\n",
      "200000 [-0.64211126 -0.81527112  1.11590624  1.72609786] 0.49939584552736943\n",
      "iteration: 200000, alfa: 0.0005\n",
      "200000 [-2.77073502 -0.99580097  0.56651774  3.26760958] 0.40582549675794055\n",
      "iteration: 200000, alfa: 1e-05\n",
      "200000 [ 0.14828921 -0.69312022  0.77938409  1.2130416 ] 0.5686151049525676\n",
      "iteration: 300000, alfa: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-7d5907c1794a>:2: RuntimeWarning: divide by zero encountered in log\n",
      "  err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
      "<ipython-input-10-7d5907c1794a>:2: RuntimeWarning: invalid value encountered in multiply\n",
      "  err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000 [-56.20163494  -5.26790425 -15.51900064  45.4697445 ] nan\n",
      "iteration: 300000, alfa: 0.01\n",
      "300000 [-20.12046178  -2.20554145  -5.06338174  16.65513544] 0.18225133394128204\n",
      "iteration: 300000, alfa: 0.05\n",
      "300000 [-42.5800683   -4.1712129  -11.56628057  34.75687729] 0.10108473054739604\n",
      "iteration: 300000, alfa: 0.001\n",
      "300000 [-5.90935598 -1.08770924 -0.62102637  5.36106613] 0.3250047511493259\n",
      "iteration: 300000, alfa: 0.005\n",
      "300000 [-13.94271361  -1.67368577  -3.20717389  11.64580974] 0.22733631787969832\n",
      "iteration: 300000, alfa: 0.0001\n",
      "300000 [-0.95624035 -0.87644457  1.10163265  2.00543623] 0.48128705597746324\n",
      "iteration: 300000, alfa: 0.0005\n",
      "300000 [-3.76552928 -1.01496641  0.17888788  3.90129243] 0.3748915448629178\n",
      "iteration: 300000, alfa: 1e-05\n",
      "300000 [ 0.06280227 -0.6861149   0.85151128  1.21295643] 0.5559828664575783\n",
      "Лучшие параметры iteration=200000, alfa=0.1 со значением err=0.09156004715343082\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_param([10000, 50000, 100000, 150000, 200000, 300000], [0.1, 0.01, 0.05, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 [-47.83523093  -4.60958703 -13.08107424  38.92379106] 0.09156004715343082\n"
     ]
    }
   ],
   "source": [
    "W, err = eval_model(X_st, y, iterations=200000, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(W, X):\n",
    "    z = np.dot(W, X)\n",
    "    y_pred_proba = [sigmoid(z)]   \n",
    "    return y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.33027502, 0.00223262, 1.        , 0.03215065, 0.96673777,\n",
       "        0.01491352, 1.        , 0.00807259, 0.65518501, 1.        ])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_pred_proba(W, X_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. cоздайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(W, X):\n",
    "    z = np.dot(W, X)\n",
    "    y_pred = sigmoid(z)\n",
    "    return np.around(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = calc_pred(W, X_st)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, могла, тк много итераций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
